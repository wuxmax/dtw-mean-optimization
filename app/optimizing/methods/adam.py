import numpy as np
from optimizing.interface import get_subgradient
from optimizing.dtw_mean import frechet

from numba import jit

""" 
Require: Î±: Stepsize
Require: Î²1, Î²2 âˆˆ [0, 1): Exponential decay rates for the moment estimates
Require: f(Î¸): Stochastic objective function with parameters Î¸
Require: Î¸0: Initial parameter vector
m0 â† 0 (Initialize 1st moment vector)
v0 â† 0 (Initialize 2nd moment vector)
t â† 0 (Initialize timestep)
while Î¸t not converged do
    t â† t + 1
    gt â† âˆ‡Î¸ft(Î¸tâˆ’1) (Get gradients w.r.t. stochastic objective at timestep t)
    mt â† Î²1 Â· mtâˆ’1 + (1 âˆ’ Î²1) Â· gt (Update biased first moment estimate)
    vt â† Î²2 Â· vtâˆ’1 + (1 âˆ’ Î²2) Â· g2t (Update biased second raw moment estimate)
    mbt â† mt/(1 âˆ’ Î²t1) (Compute bias-corrected first moment estimate)
    vbt â† vt/(1 âˆ’ Î²t2) (Compute bias-corrected second raw moment estimate)
    Î¸t â† Î¸tâˆ’1 âˆ’ Î± Â· mb t/(âˆšvbt + eps) (Update parameters)
end while
return Î¸t (Resulting parameters)
"""

# run(X, z, f, batch_size, n_epochs, progress_bar)
@jit
def run(X, z, f, batch_size, n_epochs, progress_bar):
    N = X.shape[0]
    d = z.shape
    n_steps = int(np.floor(n_epochs * N / batch_size))

    alpha = 0.001
    beta1 = 0.9
    beta2 = 0.999
    eps_stable = 1e-8

    m = np.zeros((n_steps + 1,) + d)
    v = np.zeros((n_steps + 1,) + d)
    
    for k in range(n_epochs):
        # shuffle data indices for new epoch
        perm = np.random.permutation(N)

        for i in range(0, N, batch_size):
            # break if there is not an entire batch left 
            # (relevant for batch_size > 1)
            if N - i < batch_size:
                break

            # update step index (+1 indexed, because of m, v initialization)
            t = k * N + i * batch_size + 1

            # get_subgradient(X, z, data_idx, batch_size, perm)
            g = get_subgradient(X, z, i, batch_size, perm)

            m[t] = beta1 * m[t - 1] + (1 - beta1) * g
            v[t] = beta2 * v[t - 1] + (1 - beta2) * np.square(g)

            m_ = m[t] / (1 - np.power(beta1, t))
            v_ = v[t] / (1 - np.power(beta2, t))
            
            # actual update step
            z = z - alpha * m_ / (np.sqrt(v_) + eps_stable)

            # only for updating the terminal progess bar
            progress_bar.update(batch_size)
        
        # f[0] is initial value, therefore +1 indexed
        f[k + 1] = frechet(z, X)

    return z, f

        